BDEPEND=python_targets_python3_10? ( dev-lang/python:3.10 ) >=dev-python/gpep517-15[python_targets_python3_10(-)?] >=dev-python/setuptools-69.0.3[python_targets_python3_10(-)?]
DEFINED_PHASES=compile configure install prepare test
DESCRIPTION=Apache Spark Python API
EAPI=8
HOMEPAGE=https://github.com/apache/spark/tree/master/python
INHERIT=distutils-r1
IUSE=python_targets_python3_10
KEYWORDS=~amd64
LICENSE=Apache-2.0
RDEPEND=>=dev-java/spark-core-3.0.0 >=dev-python/pyarrow-1.0.0[python_targets_python3_10(-)?] >=dev-python/numpy-1.7[python_targets_python3_10(-)?] >=dev-python/pandas-0.23.2[python_targets_python3_10(-)?] >=dev-python/py4j-0.10.9[python_targets_python3_10(-)?] python_targets_python3_10? ( dev-lang/python:3.10 )
REQUIRED_USE=|| ( python_targets_python3_10 )
SLOT=0
SRC_URI=mirror://pypi/p/pyspark/pyspark-3.1.2.tar.gz
_eclasses_=toolchain-funcs	e56c7649b804f051623c8bc1a1c44084	multilib	c19072c3cd7ac5cb21de013f7e9832e0	flag-o-matic	e503ea5acc20410237ba33ec3f7c857d	out-of-source-utils	1a9007554652a6e627edbccb3c25a439	multibuild	d67e78a235f541871c7dfe4cf7931489	multiprocessing	30ead54fa2e2b5f9cd4e612ffc34d0fe	ninja-utils	2df4e452cea39a9ec8fb543ce059f8d6	python-utils-r1	8b220bbce5c119fb1d4d5c2f5588f3ea	python-r1	428f5c53276c2adc06a89108fc2f9f46	distutils-r1	f11e1bc907da246e941fbae648327823
_md5_=6ff284009f93c4bf9450d070d74a8749
