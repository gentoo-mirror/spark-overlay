BDEPEND=python_targets_python3_10? ( dev-lang/python:3.10 ) >=dev-python/gpep517-15[python_targets_python3_10(-)?] >=dev-python/setuptools-69.0.3[python_targets_python3_10(-)?]
DEFINED_PHASES=compile configure install prepare test
DESCRIPTION=Apache Spark Python API
EAPI=8
HOMEPAGE=https://github.com/apache/spark/tree/master/python
INHERIT=distutils-r1
IUSE=python_targets_python3_10
KEYWORDS=~amd64
LICENSE=Apache-2.0
RDEPEND=>=dev-java/spark-core-3.0.0 >=dev-python/pyarrow-1.0.0[python_targets_python3_10(-)?] >=dev-python/numpy-1.7[python_targets_python3_10(-)?] >=dev-python/pandas-0.23.2[python_targets_python3_10(-)?] >=dev-python/py4j-0.10.9[python_targets_python3_10(-)?] python_targets_python3_10? ( dev-lang/python:3.10 )
REQUIRED_USE=|| ( python_targets_python3_10 )
SLOT=0
SRC_URI=mirror://pypi/p/pyspark/pyspark-3.1.2.tar.gz
_eclasses_=toolchain-funcs	6afdb6107430c1832ca7e16aacbf8fa1	multilib	b2a329026f2e404e9e371097dda47f96	flag-o-matic	357f1a896fbedcd06e5ce55419c49eb9	out-of-source-utils	dbf9e34ee8964084651e25907fa8f52c	multibuild	4650a65187015567b4e041bb9bfdb364	multiprocessing	1e32df7deee68372153dca65f4a7c21f	ninja-utils	2df4e452cea39a9ec8fb543ce059f8d6	python-utils-r1	b7726144f5af59e186d66746d0f513e5	python-r1	fa2daad0051275fa416115c76e53b1de	distutils-r1	85ccd3b54a6533fb120ee52b7c76a3df
_md5_=6ff284009f93c4bf9450d070d74a8749
