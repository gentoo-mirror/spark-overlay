BDEPEND=python_targets_python3_10? ( dev-lang/python:3.10 ) >=dev-python/gpep517-16[python_targets_python3_10(-)?] >=dev-python/setuptools-78.1.0[python_targets_python3_10(-)?]
DEFINED_PHASES=compile configure install prepare test
DESCRIPTION=Apache Spark Python API
EAPI=8
HOMEPAGE=https://github.com/apache/spark/tree/master/python
INHERIT=distutils-r1
IUSE=python_targets_python3_10
KEYWORDS=~amd64
LICENSE=Apache-2.0
RDEPEND=>=dev-java/spark-core-3.0.0 >=dev-python/pyarrow-1.0.0[python_targets_python3_10(-)?] >=dev-python/numpy-1.7[python_targets_python3_10(-)?] >=dev-python/pandas-0.23.2[python_targets_python3_10(-)?] >=dev-python/py4j-0.10.9[python_targets_python3_10(-)?] python_targets_python3_10? ( dev-lang/python:3.10 )
REQUIRED_USE=|| ( python_targets_python3_10 )
SLOT=0
SRC_URI=mirror://pypi/p/pyspark/pyspark-3.1.2.tar.gz
_eclasses_=toolchain-funcs	f9d71a6efe9d083aec750dd13968e169	flag-o-matic	e8de74bac929ba17427e740e95707d00	out-of-source-utils	dbf9e34ee8964084651e25907fa8f52c	multibuild	4650a65187015567b4e041bb9bfdb364	multilib	b2a329026f2e404e9e371097dda47f96	multiprocessing	1e32df7deee68372153dca65f4a7c21f	ninja-utils	2df4e452cea39a9ec8fb543ce059f8d6	python-utils-r1	d1be7a6de225276141d669742d56f3f3	python-r1	fa2daad0051275fa416115c76e53b1de	distutils-r1	e00a374020e6ed96997e27ad9902706d
_md5_=6ff284009f93c4bf9450d070d74a8749
